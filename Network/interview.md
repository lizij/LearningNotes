# 计算机网络面试题
[TOC]
# HTTP

## 概念

HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。

HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。它是应用层的面向对象的协议。

HTTP协议工作于客户端-服务端架构为上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求后，向客户端发送响应信息

## 特点

1. **简单快速**：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 
2. **灵活**：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 
3. **无连接**：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 
4. **无状态**：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快

## 消息

### 请求

客户端发送一个HTTP请求到服务器的请求消息包括以下格式：

请求行（request line），请求头部（header），空行和请求数据四个部分组成。 
![image](http://upload-images.jianshu.io/upload_images/2964446-fdfb1a8fce8de946.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&_=5984001)

例如

```
请求行
GET /562f25980001b1b106000338.jpg HTTP/1.1

请求头部
Host    img.mukewang.com
User-Agent    Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36
Accept    image/webp,image/*,*/*;q=0.8
Referer    http://www.imooc.com/
Accept-Encoding    gzip, deflate, sdch
Accept-Language    zh-CN,zh;q=0.8

空行
请求数据
```

### 响应

 HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文

![image](http://upload-images.jianshu.io/upload_images/2964446-1c4cab46f270d8ee.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&_=5984001)

## 状态码

**1xx：指示信息–表示请求已接收，继续处理**

**2xx：成功–表示请求已被成功接收、理解、接受**

**3xx：重定向–要完成请求必须进行更进一步的操作**

**4xx：客户端错误–请求有语法错误或请求无法实现**

**5xx：服务器端错误–服务器未能实现合法的请求**



常见状态码

| 状态码                    | 解释                                                         |
| ------------------------- | ------------------------------------------------------------ |
| 100 Continue              | 客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应 |
| 101 Switching Protocols   | 服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源 |
| 200 OK                    | 客户端请求成功                                               |
| 301 Moved Permanently     | 被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的 |
| 302 Move temporarily      | 请求的资源临时从不同的URI响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 |
| 304 Not Modified          | 如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾 |
| 400 Bad Request           | 客户端请求有语法错误，不能被服务器所理解                     |
| 401 Unauthorized          | 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 |
| 403 Forbidden             | 服务器收到请求，但是拒绝提供服务                             |
| 404 Not Found             | 请求资源不存在，举个例子：输入了错误的URL                    |
| 500 Internal Server Error | 服务器发生不可预期的错误                                     |
| 503 Server Unavailable    | 服务器当前不能处理客户端的请求，一段时间后可能恢复正常，举个例子：HTTP/1.1 200 OK（CRLF） |
|                           |                                                              |

[面试必考之http状态码有哪些](https://zhuanlan.zhihu.com/p/34648453)

## 原理

1. 客户端连接到Web服务器

   一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接

2. 发送HTTP请求

   通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由**请求行、请求头部、空行和请求数据**4部分组成

3. 服务器接受请求并返回HTTP响应

   Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由**状态行、响应头部、空行和响应数据**4部分组成。

4. 释放TCP连接

   若connection 模式为**close**，则**服务器主动关闭TCP连接，客户端被动关闭连接**，释放TCP连接;若connection 模式为**keepalive**，则该**连接会保持一段时间**，在该时间内可以继续接收请求;

   > Httpd守护进程，一般都提供了keep-alive timeout时间设置参数。比如nginx的keepalive_timeout，和Apache的KeepAliveTimeout。这个keepalive_timout时间值意味着：一个http产生的tcp连接在传送完最后一个响应后，还需要hold住keepalive_timeout秒后，才开始关闭这个连接。
   >
   > 当httpd守护进程发送完一个响应后，理应马上主动关闭相应的tcp连接，设置 keepalive_timeout后，httpd守护进程会想说：”再等等吧，看看浏览器还有没有请求过来”，这一等，便是keepalive_timeout时间。如果守护进程在这个等待的时间里，一直没有收到浏览发过来http请求，则关闭这个http连接

5. 客户端浏览器解析HTML内容

   客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示

## GET和POST的区别

1. GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&相连，如`EditPosts.aspx?name=test1&id=123456`. POST方法是把提交的数据放在HTTP包的Body中.
2. GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制.
3. GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值。
4. GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码.
5. GET请求只能进行url编码，而POST支持多种编码方式

## 1.0，1.1和2.0对比

1. 是否支持长连接

   HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。

   HTTP是基于TCP/IP协议的，创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。

2. 节约带宽

   HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。

   这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。

   另外HTTP 1.1还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础

3. Host域

   现在的web server例如tomat，设置虚拟站点是非常常见的，也即是说，web server上的多个虚拟站点可以共享同一个ip和端口。

   HTTP1.0是没有host域的，HTTP1.1才支持这个参数。

4. 多路复用

   HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。

   当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。

   TCP连接有一个预热和保护的过程，先检查数据是否传送成功，一旦成功过，则慢慢加大传输速度。因此对应瞬时并发的连接，服务器的响应就会变慢。所以最好能使用一个建立好的连接，并且这个连接可以支持瞬时并发的请求。

5. 数据压缩

   HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快

6. 服务器推送

   当我们对支持HTTP2.0的web server请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源。

   服务器端推送的这些资源其实存在客户端的某处地方，客户端直接从本地加载这些资源就可以了，不用走网络，速度自然是快很多的。

[HTTP1.0 HTTP 1.1 HTTP 2.0主要区别](https://blog.csdn.net/linsongbin1/article/details/54980801)

# DNS

## 解析过程

![DNS域名解析的全过程](http://www.maixj.net/wp-content/uploads/2015/10/dns.jpg)

* 递归解析，要求域名服务器系统**一次性完成全部名字和地址之间的映射**。换句话说，解析程序期望服务器提供最终解答，若服务器是该域名的授权服务器，就检查其数据库并相应；若服务器不是授权服务器，该服务器就将请求发送给另一个服务器并等待响应，直接查找该域名授权服务器，并把响应的结果发送给请求的客户。
* 迭代解析，**每次请求一个服务器，不行在请求别的服务器**。换言之，若服务器是该域名的授权服务器，就检查其数据库并响应，完成解析；若不是，就返回认为可以解析这个查询的服务器的IP地址。客户像第二个服务器查询，若新找到的服务器能解决这个问题，就响应并完成解析；否则，就向客户返回一个新服务器的IP地址。客户如此重复查询，直到找到该域名授权服务器。

## 为什么同时使用TCP和UDP

### 使用场景

DNS在进行区域传送的时候使用TCP协议，其它时候则使用UDP协议

> 区域传送：DNS的规范规定了2种类型的DNS服务器，一个叫主DNS服务器，一个叫辅助DNS服务器。在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫做区域传送（zone transfer）

**TCP与UDP传送字节的长度限制：** 
UDP报文的最大长度为512字节，而TCP则允许报文长度超过512字节。当DNS查询超过512字节时，协议的TC标志出现删除标志，这时则使用TCP发送。通常传统的UDP报文一般不会大于512字节。 

区域传送时使用TCP，主要有以下两点考虑： 

1. 辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，则会执行一次区域传送，进行数据同步。区域传送将使用TCP而不是UDP，因为数据同步传送的数据量比一个请求和应答的数据量要多得多。 
2. TCP是一种可靠的连接，保证了数据的准确性。 

域名解析时使用UDP协议： 
客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样DNS服务器负载更低，响应更快。虽然从理论上说，客户端也可以指定向DNS服务器查询的时候使用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。

[DNS分别在什么情况下使用UDP和TCP](http://www.cnblogs.com/549294286/p/5172435.html)

# OSI

![image](http://hi.csdn.net/attachment/201201/5/0_1325744597WM32.gif)

# SSL

## 握手过程

![img](https://upload-images.jianshu.io/upload_images/128529-abd6f1e1e6e126b5.jpg)

1. 客户端发送随机数1，支持的加密方法（如RSA公钥加密）
2. 服务端发送随机数2，并确认加密方法
3. 服务端将自己的证书下发给客户端，让客户端验证自己的身份
4. 客户端先从 CA 验证该证书的合法性，验证通过后取出证书中的服务端公钥，发送用服务器公钥加密的随机数3
5. 服务器用私钥解密这个随机数3，至此两边都拥有3个随机数
6. 两边根据同样的算法就可以生成一份秘钥，握手结束后的应用层数据都是使用这个秘钥进行对称加密接下来的报文都用双方协定好的加密方法和密钥，进行加密

[SSL/TLS 握手过程详解](https://www.jianshu.com/p/7158568e4867)

## HTTPS

HTTPS = HTTP + 一组对称、非对称和基于证书的加密技术 
HTTPS是最常见的HTTP安全版本。它得到了很广泛的应用，所有主要的商业浏览器和服务器都提供HTTPS。HTTPS将HTTP协议与一组强大的对称、非对称和基于证书的加密技术结合在一起，使得HTTPS不仅很安全，而且很灵活，很容易在出于无序状态的、分散的全球互联网上进行管理

### HTTPS通信过程

1. 建立服务器443端口连接
2. SSL握手：随机数，证书，密钥，加密算法
3. 发送加密请求
4. 发送加密响应
5. 关闭SSL
6. 关闭TCP

### HTTP和HTTPS对比

![img](http://img.blog.csdn.net/20170319110021928?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTmV3RmlzaENvZGVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![https与http连接过程区别](http://img.blog.csdn.net/20170319105852279?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTmV3RmlzaENvZGVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

[HTTPS和SSL握手过程](http://blog.csdn.net/newfishcoder/article/details/63682747)

# TCP和UDP

## TCP

### 结构

![image](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1494505577&di=cd1d044f1f8c9f2ec8af35ed1281faad&imgtype=jpg&er=1&src=http%3A%2F%2Fs8.sinaimg.cn%2Fmiddle%2F6124a935gae861dce5017%26amp%3B690)

### 三次握手过程

序号为seq，确认号为ack

1. 建立连接时,客户端发送SYN包（seq=J）到服务器,并进入SYN_SEND状态,等待服务器确认


2. 服务器收到SYN包,回复SYN+ACK（seq=K，ack=J+1）,此时服务器进入SYN_RECV状态
3. 客户端收到服务器的SYN＋ACK包,向服务器发送确认包ACK（ack=K+1）,此包发送完毕,客户端和服务器进入ESTABLISHED状态,完成三次握手

![img](http://blog.chinaunix.net/attachment/201304/8/22312037_1365405910EROI.png)

> 需要第三次握手的原因在于Server端在第二次握手（发出信息）后并不知道对方是否能接收、己方的发送功能是否正常。但此时数据的单向通道已经建立，对于CLient来说，已经确认了Server端可以接受信号，因此可以单向给Server发送数据了

> SYN攻击
>
> 在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将产时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击时一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了

### 四次挥手

#### 过程

四次挥手（Four-Way Wavehand）即终止TCP连接，就是指断开一个TCP连接时，需要客户端和服务端总共发送4个包以确认连接的断开。在socket编程中，这一过程由客户端或服务端任一方执行close来触发，整个流程如下图所示

![image](http://upload-images.jianshu.io/upload_images/2964446-2b9562b3a8b72fb2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

1. 第一次挥手：Client发送一个FIN（seq=M），用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。
2. 第二次挥手：Server收到FIN后，发送一个ACK（ack=M+1）给Client，Server进入CLOSE_WAIT状态。
3. 第三次挥手：Server发送一个FIN+ACK（seq=K，ack=M+1），用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。
4. 第四次挥手：Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK（seq=M+1，ack=K+1）给Server，Server进入CLOSED状态，完成四次挥手。在TIME_WAIT状态中，如果TCP client端最后一次发送的ACK丢失了，它将重新发送

> TCP是全双工的，每一个方向都必须单独进行开关，所以需要四次握手。而建立连接时发起者A的两个方向是默认打开的，B可以省去一个通知A打开的请求，所以只需要三次握手
>
> 服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送
>

#### TIME_WAIT

##### 为什么需要TIME_WAIT状态

假设最后的ACK丢失，server将重发FIN，client必须维护TCP状态信息以便可以重发最后的ACK，否则将会发送RST，结果server认为发生错误。TCP实现必须可靠地终止连接的两个方向，所以client必须进入TIME_WAIT状态

##### 为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态

1. 保证TCP协议的全双工连接能够可靠关闭 

   如果Client直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致Server没有收到Client最后回复的ACK。那么Server就会在超时之后继续发送FIN，此时由于Client已经CLOSED了，就找不到与重发的FIN对应的连接，最后Server就会收到RST而不是ACK，Server就会以为是连接错误把问题报告给高层。这样的情况虽然不会造成数据丢失，但是却导致TCP协议不符合可靠连接的要求。所以，Client不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。

2. 保证这次连接的重复数据段从网络中消失
  如果Client直接CLOSED，然后又再向Server发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达Server，由于新连接和老连接的端口号是一样的，又因为TCP协议判断不同连接的依据是socket pair，于是，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失

### 滑动窗口

#### 原理

在接收端存在一个**接收缓存区，用来接收来自于发送方的数据**，只有当应用进程从接收缓存区中取出数据（可能只是部分）并发出其ACK后，才算作这部分数据已经接收，然后调节此时的滑动窗口大小。**发送方根据返回的窗口大小，计算出所能发送的数据大小**。因此，可以这么理解，滑动窗口算法是接收端作为主动方根据自身的缓存以及处理能力主动去调节对方的发送流量的一种调节算法

#### 如何保证可靠性和顺序性

1. 应用数据被分割成TCP认为的最合适发送的数据块
2. 当TCP发出一个报文段后，就启动一个定时器，用来等待目的端确认收到这个报文段；若没能及时收到这个确认，TCP发送端将重新发送这个报文段（超时重传）；
3. TCP收到一个发自TCP连接的另一端的数据后就将发送一个确认，不过这个确认不是立即就发送，而是要推迟几分之一秒后才发送；
4. TCP将保持它的首部和数据的检验和；（这是一个端到端的检验和，为了检验数据在传输过程中发生的错误；若检测到段的检验和有差错，TCP将丢弃和不确认收到此报文段并希望发端可以进行超时重传）
5. 由于TCP报文段是作为IP数据报来传输的，又因为IP数据报的到达可能会失序，所以TCP报文段的到达也可能会失序；因此，有必要的话TCP会对收到的数据进行重新排序后交给应用层；
6. 因为TCP报文段是作为IP数据报来传输的，并且IP数据报可能会发生重复，所以TCP的接收端必须丢弃掉重复的数据；
7. TCP提供流量控制，因为TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这一限制可以防止较快主机致使较慢主机的缓冲区溢出

### 粘包问题

TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾

#### 产生原因

1. 发送方原因

   我们知道，TCP默认会使用Nagle算法。而Nagle算法主要做两件事：1）只有上一个分组得到确认，才会发送下一个分组；2）收集多个小分组，在一个确认到来时一起发送。所以，正是Nagle算法造成了发送方有可能造成粘包现象。

   即**发送端需要等缓冲区满才发送出去，造成粘包**

2. 接收方原因

   TCP接收到分组时，并不会立刻送至应用层处理，或者说，应用层并不一定会立即处理；实际上，TCP将收到的分组保存至接收缓存里，然后应用程序主动从缓存里读收到的分组。这样一来，如果TCP接收分组的速度大于应用程序读分组的速度，多个包就会被存至缓存，应用程序读时，就会读到多个首尾相接粘到一起的包

   即**接收方不及时接收缓冲区的包，造成多个包接收**

#### 处理方式

1. 发送方

   可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满。

   这种编程设置方法虽然可以避免发送方引起的粘包，但它关闭了优化算法，降低了网络发送效率，影响应用程序的性能，一般不建议使用

2. 接收方

   可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象，这样只能减少出现粘包的可能性，但并不能完全避免粘包，当发送频率较高时，或由于网络突发可能使某个时间段数据包到达接收方较快，接收方还是有可能来不及接收，从而导致粘包。

   或者由接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包。这样虽然避免了粘包，但应用程序的效率较低，对实时应用的场合不适合

一种比较周全的对策是：**接收方创建一预处理线程，对接收到的数据包进行预处理，将粘连的包分开。**

### 编程一般步骤

#### 服务器

1. 创建一个socket，用函数socket()；
2. 设置socket属性，用函数setsockopt(); * 可选
3. 绑定IP地址、端口等信息到socket上，用函数bind();
4. 开启监听，用函数listen()；
5. 接收客户端上来的连接，用函数accept()；
6. 收发数据，用函数send()和recv()，或者read()和write();
7. 关闭网络连接；
8. 关闭监听；

#### 客户端

1. 创建一个socket，用函数socket()；
2. 设置socket属性，用函数setsockopt();* 可选
3. 绑定IP地址、端口等信息到socket上，用函数bind();* 可选
4. 设置要连接的对方的IP地址和端口等属性；
5. 连接服务器，用函数connect()；
6. 收发数据，用函数send()和recv()，或者read()和write();
7. 关闭网络连接；

## UDP

### 基本概念

User Data Protocol，用户数据报协议

1. UDP是一个非连接的协议，传输数据之前源端和终端不建立连接，当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。在发送端，UDP传送数据的速度仅仅是受应用程序生成数据的速度、计算机的能力和传输带宽的限制；在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。
2. 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等，因此一台服务机可同时向多个客户机传输相同的消息。
3. UDP信息包的标题很短，只有8个字节，相对于TCP的20个字节信息包的额外开销很小。
4. 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制。
5. UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态表（这里面有许多参数。
6. UDP是面向报文的。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界。

### 编程一般步骤

#### 服务器

1、创建一个socket，用函数socket()；

2、设置socket属性，用函数setsockopt();* 可选

3、绑定IP地址、端口等信息到socket上，用函数bind();

4、循环接收数据，用函数recvfrom();

5、关闭网络连接；

#### 客户端

1. 创建一个socket，用函数socket()；
2. 设置socket属性，用函数setsockopt();* 可选
3. 绑定IP地址、端口等信息到socket上，用函数bind();* 可选
4. 设置对方的IP地址和端口等属性;
5. 发送数据，用函数sendto();
6. 关闭网络连接；

## TCP和UDP区别

1. TCP是传输控制协议，面向字节流，提供拥塞控制功能；UDP是用户数据报协议，面向报文，尽最大努力交付数据
2. TCP是面向连接的协议，UDP是面向非连接的协议
3. TCP是传输可靠型协议，UDP是传输不可靠型协议
4. TCP的速度较慢，UDP的速度较快

# 拥塞控制和流量控制

## 流量控制

所谓流量控制就是让发送速率不要过快，让接收方来得及接收。利用滑动窗口机制就可以实施流量控制。原理就是运用TCP报文段中的窗口大小字段来控制，**发送方的发送窗口不可以大于接收方发回的窗口大小**。

考虑一种特殊的情况，就是接收方若没有缓存足够使用，就会发送零窗口大小的报文，此时发送放将发送窗口设置为0，停止发送数据。之后接收方有足够的缓存，发送了非零窗口大小的报文，但是这个报文在中途丢失的，那么发送方的发送窗口就一直为零导致死锁。

解决这个问题，TCP为每一个连接设置一个持续计时器（persistence timer）。只要TCP的一方收到对方的零窗口通知，就启动该计时器，**周期性的发送一个零窗口探测报文段**。对方就在确认这个报文的时候给出现在的窗口大小（注意：TCP规定，即使设置为零窗口，也必须接收以下几种报文段：零窗口探测报文段、确认报文段和携带紧急数据的报文段）。

## 拥塞控制

在某段时间，若对网络中的某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变化，这种情况叫做拥塞。

所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能承受现有的网络负荷。

流量控制往往指的是点对点通信量的控制，是个端到端的问题。流量控制所要做的就是控制发送端发送数据的速率，以便使接收端来得及接受。

因特网建议标准RFC2581定义了进行拥塞控制的四种算法，即**慢开始（Slow-start)，拥塞避免（Congestion Avoidance)，快重传（Fast Restrangsmit）和快回复（Fast Recovery）**。

### 慢开始和拥塞避免

拥塞避免：发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，**发送窗口可能小于拥塞窗口**。

慢开始：不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。

### 快重传和快恢复

快重传要求接收方**在收到一个失序的报文段后就立即发出重复确认**（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要**一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期**。

一条TCP连接有时会因等待重传计时器的超时而空闲较长的时间，慢开始和拥塞避免无法很好的解决这类问题，因此提出了快重传和快恢复的拥塞控制方法。

快重传算法并非取消了重传机制，只是在某些情况下更早的重传丢失的报文段（如果当发送端接收到三个重复的确认ACK时，则断定分组丢失，立即重传丢失的报文段，而不必等待重传计时器超时）。慢开始算法只是在TCP建立时才使用

[TCP的拥塞控制](http://blog.csdn.net/sicofield/article/details/9708383)

[TCP/IP详解学习笔记（15）-- TCP的流量控制和拥塞控制](http://www.cnblogs.com/newwy/p/3254029.html)

